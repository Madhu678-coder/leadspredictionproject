{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "428c1ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minfy.CHILUKURIVASUSR\\Desktop\\Lead Prediction\\leadscoring_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Minfy.CHILUKURIVASUSR\\Desktop\\Lead Prediction\\leadscoring_venv\\lib\\site-packages\\mlflow\\protos\\service_pb2.py:11: UserWarning: google.protobuf.service module is deprecated. RPC implementations should provide code generator plugins which generate code specific to the RPC implementation. service.py will be removed in Jan 2025\n",
      "  from google.protobuf import service as _service\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# üì¶ Data Handling\n",
    "# ==============================\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# ==============================\n",
    "# üóÑÔ∏è Database Connection\n",
    "# ==============================\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# ==============================\n",
    "# üîß Preprocessing & ML\n",
    "# ==============================\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# ==============================\n",
    "# üìä Metrics\n",
    "# ==============================\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "# if you have your own metric helpers:\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    log_loss\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# üé® Visualization\n",
    "# ==============================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==============================\n",
    "# üîç Explainability\n",
    "# ==============================\n",
    "import shap\n",
    "\n",
    "# ==============================\n",
    "# üìà Monitoring with Evidently\n",
    "# ==============================\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "\n",
    "# ==============================\n",
    "# üöÄ MLflow Tracking\n",
    "# ==============================\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# ==============================\n",
    "# üíæ Model Persistence\n",
    "# ==============================\n",
    "import joblib\n",
    "\n",
    "# ==============================\n",
    "# ‚ö†Ô∏è Suppress warnings\n",
    "# ==============================\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='_distutils_hack')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457555d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data uploaded to PostgreSQL table 'lead' successfully.\n",
      "‚úÖ Data retrieved from PostgreSQL table 'lead':\n",
      "                            Prospect ID  Lead Number              Lead Origin  \\\n",
      "0  7927b2df-8bba-4d29-b9a2-b6e0beafe620       660737                      API   \n",
      "1  2a272436-5132-4136-86fa-dcc88c88f482       660728                      API   \n",
      "2  8cc8c611-a219-4f35-ad23-fdfd2656bd8a       660727  Landing Page Submission   \n",
      "3  0cc2df48-7cf4-4e39-9de9-19797f9b38cc       660719  Landing Page Submission   \n",
      "4  3256f628-e534-4826-9d63-4a8b88782852       660681  Landing Page Submission   \n",
      "\n",
      "      Lead Source Do Not Email Do Not Call  Converted  TotalVisits  \\\n",
      "0      Olark Chat           No          No          0          0.0   \n",
      "1  Organic Search           No          No          0          5.0   \n",
      "2  Direct Traffic           No          No          1          2.0   \n",
      "3  Direct Traffic           No          No          0          1.0   \n",
      "4          Google           No          No          1          2.0   \n",
      "\n",
      "   Total Time Spent on Website  Page Views Per Visit  ...  \\\n",
      "0                            0                   0.0  ...   \n",
      "1                          674                   2.5  ...   \n",
      "2                         1532                   2.0  ...   \n",
      "3                          305                   1.0  ...   \n",
      "4                         1428                   1.0  ...   \n",
      "\n",
      "  Get updates on DM Content    Lead Profile    City  \\\n",
      "0                        No          Select  Select   \n",
      "1                        No          Select  Select   \n",
      "2                        No  Potential Lead  Mumbai   \n",
      "3                        No          Select  Mumbai   \n",
      "4                        No          Select  Mumbai   \n",
      "\n",
      "  Asymmetrique Activity Index Asymmetrique Profile Index  \\\n",
      "0                   02.Medium                  02.Medium   \n",
      "1                   02.Medium                  02.Medium   \n",
      "2                   02.Medium                    01.High   \n",
      "3                   02.Medium                    01.High   \n",
      "4                   02.Medium                    01.High   \n",
      "\n",
      "  Asymmetrique Activity Score Asymmetrique Profile Score  \\\n",
      "0                        15.0                       15.0   \n",
      "1                        15.0                       15.0   \n",
      "2                        14.0                       20.0   \n",
      "3                        13.0                       17.0   \n",
      "4                        15.0                       18.0   \n",
      "\n",
      "  I agree to pay the amount through cheque  \\\n",
      "0                                       No   \n",
      "1                                       No   \n",
      "2                                       No   \n",
      "3                                       No   \n",
      "4                                       No   \n",
      "\n",
      "  A free copy of Mastering The Interview Last Notable Activity  \n",
      "0                                     No              Modified  \n",
      "1                                     No          Email Opened  \n",
      "2                                    Yes          Email Opened  \n",
      "3                                     No              Modified  \n",
      "4                                     No              Modified  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def data_ingestion(csv_file_path, table_name='lead'):\n",
    "    \"\"\"\n",
    "    This function uploads data from a CSV file to a PostgreSQL table\n",
    "    and retrieves the data back into a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        csv_file_path (str): Full path to the input CSV file.\n",
    "        table_name (str): Name of the target PostgreSQL table (default is 'lead').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing data retrieved from the PostgreSQL table,\n",
    "                      or None if an error occurs.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Step 1: Create SQLAlchemy engine to connect to PostgreSQL\n",
    "        # Format: \"postgresql+psycopg2://<username>:<password>@<host>:<port>/<database>\"\n",
    "        engine = create_engine(\"postgresql+psycopg2://postgres:Madhu14777@localhost:5432/mydb5\")\n",
    "\n",
    "        # Step 2: Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        print(f\"‚úÖ Loaded data from CSV file: {csv_file_path}\")\n",
    "\n",
    "        # Step 3: Upload the DataFrame to PostgreSQL\n",
    "        # - index=False: do not write the DataFrame index as a column\n",
    "        # - if_exists='replace': drop existing table if it exists and recreate\n",
    "        df.to_sql(table_name, con=engine, index=False, if_exists='replace')\n",
    "        print(f\"‚úÖ Data uploaded to PostgreSQL table: '{table_name}'\")\n",
    "\n",
    "        # Step 4: Read the table back into a new DataFrame to verify upload\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        df_from_db = pd.read_sql_query(query, con=engine)\n",
    "        print(f\"‚úÖ Retrieved data from table: '{table_name}'\")\n",
    "        print(df_from_db.head())  # Show preview of ingested data\n",
    "\n",
    "        return df_from_db\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print error details if any step fails\n",
    "        print(\"‚ùå Error during data ingestion or retrieval:\")\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# Usage Example\n",
    "# Ensure PostgreSQL server is running and the credentials are correct\n",
    "df = data_ingestion(\"data/Lead Scoring.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffacb4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Converted\n",
       "0    61.461039\n",
       "1    38.538961\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Converted'].value_counts(normalize=True) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "effc4e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prospect ID</th>\n",
       "      <th>Lead Number</th>\n",
       "      <th>Lead Origin</th>\n",
       "      <th>Lead Source</th>\n",
       "      <th>Do Not Email</th>\n",
       "      <th>Do Not Call</th>\n",
       "      <th>Converted</th>\n",
       "      <th>TotalVisits</th>\n",
       "      <th>Total Time Spent on Website</th>\n",
       "      <th>Page Views Per Visit</th>\n",
       "      <th>...</th>\n",
       "      <th>Get updates on DM Content</th>\n",
       "      <th>Lead Profile</th>\n",
       "      <th>City</th>\n",
       "      <th>Asymmetrique Activity Index</th>\n",
       "      <th>Asymmetrique Profile Index</th>\n",
       "      <th>Asymmetrique Activity Score</th>\n",
       "      <th>Asymmetrique Profile Score</th>\n",
       "      <th>I agree to pay the amount through cheque</th>\n",
       "      <th>A free copy of Mastering The Interview</th>\n",
       "      <th>Last Notable Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7927b2df-8bba-4d29-b9a2-b6e0beafe620</td>\n",
       "      <td>660737</td>\n",
       "      <td>API</td>\n",
       "      <td>Olark Chat</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Select</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2a272436-5132-4136-86fa-dcc88c88f482</td>\n",
       "      <td>660728</td>\n",
       "      <td>API</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>674</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Select</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Email Opened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8cc8c611-a219-4f35-ad23-fdfd2656bd8a</td>\n",
       "      <td>660727</td>\n",
       "      <td>Landing Page Submission</td>\n",
       "      <td>Direct Traffic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1532</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Potential Lead</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>01.High</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Email Opened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0cc2df48-7cf4-4e39-9de9-19797f9b38cc</td>\n",
       "      <td>660719</td>\n",
       "      <td>Landing Page Submission</td>\n",
       "      <td>Direct Traffic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>01.High</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3256f628-e534-4826-9d63-4a8b88782852</td>\n",
       "      <td>660681</td>\n",
       "      <td>Landing Page Submission</td>\n",
       "      <td>Google</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>01.High</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Modified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Prospect ID  Lead Number              Lead Origin  \\\n",
       "0  7927b2df-8bba-4d29-b9a2-b6e0beafe620       660737                      API   \n",
       "1  2a272436-5132-4136-86fa-dcc88c88f482       660728                      API   \n",
       "2  8cc8c611-a219-4f35-ad23-fdfd2656bd8a       660727  Landing Page Submission   \n",
       "3  0cc2df48-7cf4-4e39-9de9-19797f9b38cc       660719  Landing Page Submission   \n",
       "4  3256f628-e534-4826-9d63-4a8b88782852       660681  Landing Page Submission   \n",
       "\n",
       "      Lead Source Do Not Email Do Not Call  Converted  TotalVisits  \\\n",
       "0      Olark Chat           No          No          0          0.0   \n",
       "1  Organic Search           No          No          0          5.0   \n",
       "2  Direct Traffic           No          No          1          2.0   \n",
       "3  Direct Traffic           No          No          0          1.0   \n",
       "4          Google           No          No          1          2.0   \n",
       "\n",
       "   Total Time Spent on Website  Page Views Per Visit  ...  \\\n",
       "0                            0                   0.0  ...   \n",
       "1                          674                   2.5  ...   \n",
       "2                         1532                   2.0  ...   \n",
       "3                          305                   1.0  ...   \n",
       "4                         1428                   1.0  ...   \n",
       "\n",
       "  Get updates on DM Content    Lead Profile    City  \\\n",
       "0                        No          Select  Select   \n",
       "1                        No          Select  Select   \n",
       "2                        No  Potential Lead  Mumbai   \n",
       "3                        No          Select  Mumbai   \n",
       "4                        No          Select  Mumbai   \n",
       "\n",
       "  Asymmetrique Activity Index Asymmetrique Profile Index  \\\n",
       "0                   02.Medium                  02.Medium   \n",
       "1                   02.Medium                  02.Medium   \n",
       "2                   02.Medium                    01.High   \n",
       "3                   02.Medium                    01.High   \n",
       "4                   02.Medium                    01.High   \n",
       "\n",
       "  Asymmetrique Activity Score Asymmetrique Profile Score  \\\n",
       "0                        15.0                       15.0   \n",
       "1                        15.0                       15.0   \n",
       "2                        14.0                       20.0   \n",
       "3                        13.0                       17.0   \n",
       "4                        15.0                       18.0   \n",
       "\n",
       "  I agree to pay the amount through cheque  \\\n",
       "0                                       No   \n",
       "1                                       No   \n",
       "2                                       No   \n",
       "3                                       No   \n",
       "4                                       No   \n",
       "\n",
       "  A free copy of Mastering The Interview Last Notable Activity  \n",
       "0                                     No              Modified  \n",
       "1                                     No          Email Opened  \n",
       "2                                    Yes          Email Opened  \n",
       "3                                     No              Modified  \n",
       "4                                     No              Modified  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b8c509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lead Number</th>\n",
       "      <th>Converted</th>\n",
       "      <th>TotalVisits</th>\n",
       "      <th>Total Time Spent on Website</th>\n",
       "      <th>Page Views Per Visit</th>\n",
       "      <th>Asymmetrique Activity Score</th>\n",
       "      <th>Asymmetrique Profile Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9240.000000</td>\n",
       "      <td>9240.000000</td>\n",
       "      <td>9103.000000</td>\n",
       "      <td>9240.000000</td>\n",
       "      <td>9103.000000</td>\n",
       "      <td>5022.000000</td>\n",
       "      <td>5022.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>617188.435606</td>\n",
       "      <td>0.385390</td>\n",
       "      <td>3.445238</td>\n",
       "      <td>487.698268</td>\n",
       "      <td>2.362820</td>\n",
       "      <td>14.306252</td>\n",
       "      <td>16.344883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23405.995698</td>\n",
       "      <td>0.486714</td>\n",
       "      <td>4.854853</td>\n",
       "      <td>548.021466</td>\n",
       "      <td>2.161418</td>\n",
       "      <td>1.386694</td>\n",
       "      <td>1.811395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>579533.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>596484.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>615479.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>637387.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>660737.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>2272.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lead Number    Converted  TotalVisits  Total Time Spent on Website  \\\n",
       "count    9240.000000  9240.000000  9103.000000                  9240.000000   \n",
       "mean   617188.435606     0.385390     3.445238                   487.698268   \n",
       "std     23405.995698     0.486714     4.854853                   548.021466   \n",
       "min    579533.000000     0.000000     0.000000                     0.000000   \n",
       "25%    596484.500000     0.000000     1.000000                    12.000000   \n",
       "50%    615479.000000     0.000000     3.000000                   248.000000   \n",
       "75%    637387.250000     1.000000     5.000000                   936.000000   \n",
       "max    660737.000000     1.000000   251.000000                  2272.000000   \n",
       "\n",
       "       Page Views Per Visit  Asymmetrique Activity Score  \\\n",
       "count           9103.000000                  5022.000000   \n",
       "mean               2.362820                    14.306252   \n",
       "std                2.161418                     1.386694   \n",
       "min                0.000000                     7.000000   \n",
       "25%                1.000000                    14.000000   \n",
       "50%                2.000000                    14.000000   \n",
       "75%                3.000000                    15.000000   \n",
       "max               55.000000                    18.000000   \n",
       "\n",
       "       Asymmetrique Profile Score  \n",
       "count                 5022.000000  \n",
       "mean                    16.344883  \n",
       "std                      1.811395  \n",
       "min                     11.000000  \n",
       "25%                     15.000000  \n",
       "50%                     16.000000  \n",
       "75%                     18.000000  \n",
       "max                     20.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cad5107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9240 entries, 0 to 9239\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                         Non-Null Count  Dtype  \n",
      "---  ------                                         --------------  -----  \n",
      " 0   Prospect ID                                    9240 non-null   object \n",
      " 1   Lead Number                                    9240 non-null   int64  \n",
      " 2   Lead Origin                                    9240 non-null   object \n",
      " 3   Lead Source                                    9204 non-null   object \n",
      " 4   Do Not Email                                   9240 non-null   object \n",
      " 5   Do Not Call                                    9240 non-null   object \n",
      " 6   Converted                                      9240 non-null   int64  \n",
      " 7   TotalVisits                                    9103 non-null   float64\n",
      " 8   Total Time Spent on Website                    9240 non-null   int64  \n",
      " 9   Page Views Per Visit                           9103 non-null   float64\n",
      " 10  Last Activity                                  9137 non-null   object \n",
      " 11  Country                                        6779 non-null   object \n",
      " 12  Specialization                                 7802 non-null   object \n",
      " 13  How did you hear about X Education             7033 non-null   object \n",
      " 14  What is your current occupation                6550 non-null   object \n",
      " 15  What matters most to you in choosing a course  6531 non-null   object \n",
      " 16  Search                                         9240 non-null   object \n",
      " 17  Magazine                                       9240 non-null   object \n",
      " 18  Newspaper Article                              9240 non-null   object \n",
      " 19  X Education Forums                             9240 non-null   object \n",
      " 20  Newspaper                                      9240 non-null   object \n",
      " 21  Digital Advertisement                          9240 non-null   object \n",
      " 22  Through Recommendations                        9240 non-null   object \n",
      " 23  Receive More Updates About Our Courses         9240 non-null   object \n",
      " 24  Tags                                           5887 non-null   object \n",
      " 25  Lead Quality                                   4473 non-null   object \n",
      " 26  Update me on Supply Chain Content              9240 non-null   object \n",
      " 27  Get updates on DM Content                      9240 non-null   object \n",
      " 28  Lead Profile                                   6531 non-null   object \n",
      " 29  City                                           7820 non-null   object \n",
      " 30  Asymmetrique Activity Index                    5022 non-null   object \n",
      " 31  Asymmetrique Profile Index                     5022 non-null   object \n",
      " 32  Asymmetrique Activity Score                    5022 non-null   float64\n",
      " 33  Asymmetrique Profile Score                     5022 non-null   float64\n",
      " 34  I agree to pay the amount through cheque       9240 non-null   object \n",
      " 35  A free copy of Mastering The Interview         9240 non-null   object \n",
      " 36  Last Notable Activity                          9240 non-null   object \n",
      "dtypes: float64(4), int64(3), object(30)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9cf5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Lead Origin     Lead Source Do Not Email Do Not Call  \\\n",
      "0                      API      Olark Chat           No          No   \n",
      "1                      API  Organic Search           No          No   \n",
      "2  Landing Page Submission  Direct Traffic           No          No   \n",
      "3  Landing Page Submission  Direct Traffic           No          No   \n",
      "4  Landing Page Submission          Google           No          No   \n",
      "\n",
      "   Converted  TotalVisits  Total Time Spent on Website  Page Views Per Visit  \\\n",
      "0          0          0.0                            0                   0.0   \n",
      "1          0          5.0                          674                   2.5   \n",
      "2          1          2.0                         1532                   2.0   \n",
      "3          0          1.0                          305                   1.0   \n",
      "4          1          2.0                         1428                   1.0   \n",
      "\n",
      "             Last Activity Country  ...                                 Tags  \\\n",
      "0  Page Visited on Website    None  ...          Interested in other courses   \n",
      "1             Email Opened   India  ...                              Ringing   \n",
      "2             Email Opened   India  ...  Will revert after reading the email   \n",
      "3              Unreachable   India  ...                              Ringing   \n",
      "4        Converted to Lead   India  ...  Will revert after reading the email   \n",
      "\n",
      "       Lead Quality    Lead Profile    City Asymmetrique Activity Index  \\\n",
      "0  Low in Relevance          Select  Select                   02.Medium   \n",
      "1              None          Select  Select                   02.Medium   \n",
      "2          Might be  Potential Lead  Mumbai                   02.Medium   \n",
      "3          Not Sure          Select  Mumbai                   02.Medium   \n",
      "4          Might be          Select  Mumbai                   02.Medium   \n",
      "\n",
      "  Asymmetrique Profile Index Asymmetrique Activity Score  \\\n",
      "0                  02.Medium                        15.0   \n",
      "1                  02.Medium                        15.0   \n",
      "2                    01.High                        14.0   \n",
      "3                    01.High                        13.0   \n",
      "4                    01.High                        15.0   \n",
      "\n",
      "  Asymmetrique Profile Score A free copy of Mastering The Interview  \\\n",
      "0                       15.0                                     No   \n",
      "1                       15.0                                     No   \n",
      "2                       20.0                                    Yes   \n",
      "3                       17.0                                     No   \n",
      "4                       18.0                                     No   \n",
      "\n",
      "  Last Notable Activity  \n",
      "0              Modified  \n",
      "1          Email Opened  \n",
      "2          Email Opened  \n",
      "3              Modified  \n",
      "4              Modified  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "(9240, 30)\n"
     ]
    }
   ],
   "source": [
    "# Step: Drop Unwanted or Irrelevant Columns from the Dataset\n",
    "\n",
    "# Define the list of columns that are not useful for analysis or model training\n",
    "columns_to_drop = [\n",
    "    'Prospect ID',                               # Unique identifier, not useful for prediction\n",
    "    'Lead Number',                               # Same as above\n",
    "    'Get updates on DM Content',                 # Very low variance or sparse\n",
    "    'Receive More Updates About Our Courses',    # Redundant/low signal\n",
    "    'I agree to pay the amount through cheque',  # Low variance or always same\n",
    "    'Magazine',                                  # Irrelevant feature\n",
    "    'Update me on Supply Chain Content'          # Sparse or not correlated\n",
    "]\n",
    "\n",
    "# Drop these columns in-place (modify the original DataFrame)\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Log the shape and preview of the updated DataFrame\n",
    "print(\"‚úÖ Dropped unwanted columns.\")\n",
    "print(\"Updated DataFrame shape:\", df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7424e",
   "metadata": {},
   "source": [
    "### We use FunctionTransformer to integrate our custom category mappings into a Scikit-learn pipeline. It helps apply reusable logic, maintain clean code, and ensure consistency across training and prediction.\n",
    "### This preprocessing step reduces noise, improves model generalization, and keeps the pipeline clean and interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6755e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_categorical_columns(df):\n",
    "    df = df.copy()\n",
    "    city_map = {\n",
    "        'Mumbai': 'Metro India', 'Thane & Outskirts': 'Metro India', 'Other Metro Cities': 'Metro India',\n",
    "        'Other Cities of Maharashtra': 'Tier II India', 'Tier II Cities': 'Tier II India', 'Other Cities': 'Other India',\n",
    "        'Select': 'Unknown', 'nan': 'Unknown', pd.NA: 'Unknown', None: 'Unknown'\n",
    "    }\n",
    "    country_map = {\n",
    "        'India': 'India', 'United States': 'North America', 'Canada': 'North America',\n",
    "        'United Arab Emirates': 'Middle East', 'Saudi Arabia': 'Middle East', 'Qatar': 'Middle East', 'Kuwait': 'Middle East',\n",
    "        'Oman': 'Middle East', 'Bahrain': 'Middle East',\n",
    "        'Germany': 'Europe', 'France': 'Europe', 'United Kingdom': 'Europe', 'Sweden': 'Europe',\n",
    "        'Belgium': 'Europe', 'Netherlands': 'Europe', 'Switzerland': 'Europe',\n",
    "        'China': 'Asia', 'Singapore': 'Asia', 'Hong Kong': 'Asia', 'Philippines': 'Asia', 'Vietnam': 'Asia',\n",
    "        'South Africa': 'Africa', 'Nigeria': 'Africa',\n",
    "        'nan': 'Unknown', 'unknown': 'Other'\n",
    "    }\n",
    "    specialization_map = {\n",
    "        'Marketing Management': 'Marketing', 'Operations Management': 'Operations', 'Finance Management': 'Finance',\n",
    "        'Human Resource Management': 'HR', 'International Business': 'Business', 'Business Administration': 'Business', 'MBA': 'Business',\n",
    "        'IT Projects Management': 'IT', 'E-Business': 'E-Commerce', 'E-Commerce': 'E-Commerce', 'E Commerce': 'E-Commerce',\n",
    "        'Supply Chain Management': 'Operations', 'Retail Management': 'Operations', 'Banking, Investment And Insurance': 'Finance',\n",
    "        'Healthcare Management': 'Healthcare', 'Hospitality Management': 'Healthcare',\n",
    "        'Rural and Agribusiness': 'Other', 'Travel and Tourism': 'Other', 'Media and Advertising': 'Other', 'Services Excellence': 'Other',\n",
    "        'Not Specified': 'Unknown', 'Select': 'Unknown', 'nan': 'Unknown', None: 'Unknown'\n",
    "    }\n",
    "    education_source_map = {\n",
    "        'Online Search': 'Digital', 'Advertisements': 'Digital', 'Email': 'Digital', 'SMS': 'Digital', 'Social Media': 'Digital',\n",
    "        'Word Of Mouth': 'Referral', 'Student of SomeSchool': 'Referral',\n",
    "        'Multiple Sources': 'Multi-Channel', 'Other': 'Other', 'Select': 'Unknown', 'nan': 'Unknown', None: 'Unknown'\n",
    "    }\n",
    "    occupation_map = {\n",
    "        'Student': 'Student', 'Working Professional': 'Working', 'Businessman': 'Working',\n",
    "        'Housewife': 'Non-Working', 'Unemployed': 'Non-Working', 'Other': 'Unknown', 'Select': 'Unknown', 'nan': 'Unknown', None: 'Unknown'\n",
    "    }\n",
    "    tags_map = {\n",
    "        'Will revert after reading the email': 'Pending Response', 'Still Thinking': 'Pending Response', 'Interested in full time MBA': 'Pending Response',\n",
    "        'Ringing': 'Trying to Contact', 'Busy': 'Trying to Contact', 'switched off': 'Trying to Contact', 'opp hangup': 'Trying to Contact',\n",
    "        'Interested in other courses': 'Not Interested', 'Already a student': 'Not Interested', 'Lost to EINS': 'Not Interested', 'Lost to Others': 'Not Interested', 'Not doing further education': 'Not Interested',\n",
    "        'invalid number': 'Invalid Contact', 'wrong number given': 'Invalid Contact', 'number not provided': 'Invalid Contact',\n",
    "        'Diploma holder (Not Eligible)': 'Not Eligible', 'Graduation in progress': 'Not Eligible',\n",
    "        'Closed by Horizzon': 'Converted', 'Want to take admission but has financial problems': 'Financial Issue', 'in touch with EINS': 'Transferred'\n",
    "    }\n",
    "    lead_quality_map = {\n",
    "        'High in Relevance': 'High', 'Might be': 'Medium', 'Not Sure': 'Medium', 'Low in Relevance': 'Low', 'Worst': 'Low', 'nan': 'Unknown', None: 'Unknown'\n",
    "    }\n",
    "    lead_profile_map = {\n",
    "        'Potential Lead': 'Prospective', 'Other Leads': 'Prospective', 'Student of SomeSchool': 'Converted',\n",
    "        'Lateral Student': 'Converted', 'Dual Specialization Student': 'Converted', 'Select': 'Unknown', 'nan': 'Unknown', None: 'Unknown'\n",
    "    }\n",
    "\n",
    "    mappings = {\n",
    "        'City': city_map,\n",
    "        'Country': country_map,\n",
    "        'Specialization': specialization_map,\n",
    "        'How did you hear about X Education': education_source_map,\n",
    "        'What is your current occupation': occupation_map,\n",
    "        'Tags': tags_map,\n",
    "        'Lead Quality': lead_quality_map,\n",
    "        'Lead Profile': lead_profile_map\n",
    "    }\n",
    "\n",
    "    for col, mapping in mappings.items():\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: mapping.get(x, 'Unknown') if pd.notna(x) else 'Unknown')\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "    return df\n",
    "\n",
    "mapping_transformer = FunctionTransformer(map_categorical_columns, validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3222295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Number                     0.140451\n",
      "Converted                       0.471058\n",
      "TotalVisits                    19.911657\n",
      "Total Time Spent on Website     0.956450\n",
      "Page Views Per Visit            2.871793\n",
      "Asymmetrique Activity Score    -0.383380\n",
      "Asymmetrique Profile Score      0.221739\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select numerical columns\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Calculate skewness\n",
    "skewness_values = numeric_cols.skew()\n",
    "\n",
    "# Display skewness\n",
    "print(skewness_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5c5d8",
   "metadata": {},
   "source": [
    "### replace_unknowns_with_nan: Replaces string values like \"unknown\" (case-insensitive) in categorical columns with NaN so they can be treated as missing data.\n",
    "\n",
    "### handle_skewness: Applies log1p transformation to numerical columns that have high skewness (default threshold = 0.5) to normalize their distribution.\n",
    "\n",
    "### Both functions are wrapped using FunctionTransformer to integrate smoothly into an ML pipeline for consistent preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "199d5037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unknowns_with_nan(df):\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(include=['object', 'category']).columns:\n",
    "        df[col] = df[col].replace(r'(?i)unknown', np.nan, regex=True)\n",
    "    return df\n",
    "\n",
    "def handle_skewness(df, threshold=0.5):\n",
    "    df = df.copy()\n",
    "    num_cols = df.select_dtypes(include=np.number).columns\n",
    "    for col in num_cols:\n",
    "        if abs(df[col].skew()) > threshold:\n",
    "            df[col] = df[col].apply(lambda x: np.log1p(x) if pd.notnull(x) and x >= 0 else x)\n",
    "    return df\n",
    "\n",
    "replace_unknowns_transformer = FunctionTransformer(replace_unknowns_with_nan, validate=False)\n",
    "skewness_transformer = FunctionTransformer(handle_skewness, validate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e466ffd",
   "metadata": {},
   "source": [
    "This function constructs a complete Scikit-learn preprocessing pipeline tailored for tabular data that includes both numerical and categorical columns. It prepares the data for machine learning models by handling missing values, encoding, scaling, and applying custom transformations.\n",
    "\n",
    "Key Steps:\n",
    "Target Column Exclusion: Removes the target variable \"Converted\" from feature processing lists.\n",
    "\n",
    "Label Columns: Certain categorical columns (Lead Quality, Asymmetrique Activity Index, Asymmetrique Profile Index) are encoded using OrdinalEncoder instead of OneHotEncoder.\n",
    "\n",
    "Pipeline Components:\n",
    "\n",
    "üî¢ num_pipeline: Handles numerical columns with:\n",
    "\n",
    "Missing value imputation using median.\n",
    "\n",
    "Feature scaling using MinMaxScaler.\n",
    "\n",
    "üî§ cat_ohe_pipeline: Handles categorical columns (excluding label-encoded ones) with:\n",
    "\n",
    "Most frequent value imputation.\n",
    "\n",
    "One-hot encoding (with unknown handling).\n",
    "\n",
    "üî¢ cat_label_pipeline: Handles specific label columns with:\n",
    "\n",
    "Most frequent value imputation.\n",
    "\n",
    "Ordinal encoding (with unknown values handled as -1).\n",
    "\n",
    "Custom Transformers:\n",
    "\n",
    "üßπ mapping_transformer: Maps raw text fields to cleaner values.\n",
    "\n",
    "‚ùì replace_unknowns_transformer: Replaces \"unknown\" strings with NaN.\n",
    "\n",
    "üìâ skewness_transformer: Applies log transformation on skewed numerical features.\n",
    "\n",
    "Output:\n",
    "Returns a unified Scikit-learn Pipeline object that can be used for both fit and transform operations on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6843ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_full_pipeline(df):\n",
    "    target_col = \"Converted\"\n",
    "\n",
    "    label_cols = [\"Lead Quality\", \"Asymmetrique Activity Index\", \"Asymmetrique Profile Index\"]\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if target_col in numeric_cols:\n",
    "        numeric_cols.remove(target_col)\n",
    "    if target_col in categorical_cols:\n",
    "        categorical_cols.remove(target_col)\n",
    "    if target_col in label_cols:\n",
    "        label_cols.remove(target_col)\n",
    "\n",
    "    cat_ohe_cols = [col for col in categorical_cols if col not in label_cols]\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    cat_ohe_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "    ])\n",
    "\n",
    "    cat_label_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('label', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', num_pipeline, numeric_cols),\n",
    "        ('cat_ohe', cat_ohe_pipeline, cat_ohe_cols),\n",
    "        ('cat_label', cat_label_pipeline, label_cols)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "    full_pipeline = Pipeline([\n",
    "        ('mapping', mapping_transformer),\n",
    "        ('replace_unknowns', replace_unknowns_transformer),\n",
    "        ('skewness', skewness_transformer),\n",
    "        ('preprocessor', preprocessor)\n",
    "    ])\n",
    "\n",
    "    full_pipeline.set_output(transform='default')\n",
    "    return full_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad4cf98",
   "metadata": {},
   "source": [
    "''' # ------------------------------------------------------------------------------------\n",
    "# üß™ Classification Evaluation Utilities\n",
    "# These helper functions assist in evaluating the performance of classification models\n",
    "# by computing key metrics and presenting results clearly.\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "# ‚úÖ evaluate_classification_metrics(y_true, y_pred, y_proba=None, average_type='binary')\n",
    "# -----------------------------------------------------------------------------\n",
    "# This function calculates and returns a dictionary of classification metrics:\n",
    "# - accuracy   : Overall correctness of predictions.\n",
    "# - precision  : Proportion of predicted positives that are actual positives.\n",
    "# - recall     : Proportion of actual positives correctly predicted.\n",
    "# - f1_score   : Harmonic mean of precision and recall.\n",
    "# - roc_auc    : Area under the ROC curve (computed if y_proba is provided).\n",
    "#\n",
    "# Parameters:\n",
    "# - y_true       : Actual target labels.\n",
    "# - y_pred       : Predicted labels.\n",
    "# - y_proba      : Predicted probabilities (optional, for ROC AUC).\n",
    "# - average_type : Metric averaging method (useful for multi-class settings).\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# ‚úÖ print_classification_report(y_true, y_pred)\n",
    "# -----------------------------------------------------------------------------\n",
    "# This function prints a full classification report and a confusion matrix:\n",
    "# - classification_report : Includes precision, recall, f1-score for each class.\n",
    "# - confusion_matrix      : Matrix comparing true vs. predicted class labels.\n",
    "# Useful for quick and informative evaluation output.\n",
    "# ----------------------------------------------------------------------------- '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1bcbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_classification_metrics(y_true, y_pred, y_proba=None, average_type='binary'):\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, average=average_type, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, average=average_type, zero_division=0),\n",
    "        \"f1_score\": f1_score(y_true, y_pred, average=average_type, zero_division=0)\n",
    "    }\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            metrics[\"roc_auc\"] = roc_auc_score(y_true, y_proba)\n",
    "        except ValueError:\n",
    "            metrics[\"roc_auc\"] = None\n",
    "    else:\n",
    "        metrics[\"roc_auc\"] = None\n",
    "    return metrics\n",
    "\n",
    "def print_classification_report(y_true, y_pred):\n",
    "    print(\"\\n‚úÖ Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\n‚úÖ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0219c86a",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------\n",
    "# üöÇ train_log_and_shap_classification(X_train, y_train, X_val, y_val, preprocessor, ...)\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# This function:\n",
    "# ‚úÖ Trains multiple classification models using GridSearchCV with preprocessing pipeline\n",
    "# ‚úÖ Evaluates models on validation set using accuracy, precision, recall, f1, and ROC AUC\n",
    "# ‚úÖ Saves best models locally using joblib\n",
    "# ‚úÖ Logs model parameters and metrics to MLflow\n",
    "# ‚úÖ Generates and logs SHAP summary plots for model explainability\n",
    "#\n",
    "# Models included:\n",
    "# - Logistic Regression\n",
    "# - Decision Tree\n",
    "# - Random Forest\n",
    "# - XGBoost\n",
    "#\n",
    "# Parameters:\n",
    "# - X_train, y_train       : Training feature set and labels\n",
    "# - X_val, y_val           : Validation feature set and labels\n",
    "# - preprocessor           : Preprocessing pipeline (e.g., ColumnTransformer)\n",
    "# - save_dir (str)         : Directory to save best models\n",
    "# - shap_dir (str)         : Directory to save SHAP plots\n",
    "#\n",
    "# Returns:\n",
    "# - results_df (DataFrame) : Metrics summary for all models\n",
    "# - best_models (dict)     : Dictionary of best trained models per algorithm\n",
    "# ------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522abf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_log_and_shap_classification(\n",
    "    X_train, y_train, X_val, y_val, preprocessor,\n",
    "    save_dir=\"saved_models\", shap_dir=\"shap_outputs\"\n",
    "):\n",
    "    models = {\n",
    "        'LogisticRegression': {\n",
    "            'model': LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42),\n",
    "            'params': {'C': [0.1, 1.0, 10.0]}\n",
    "        },\n",
    "        'DecisionTree': {\n",
    "            'model': DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "            'params': {'max_depth': [5, 10, None], 'min_samples_split': [2, 5]}\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'model': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "            'params': {'n_estimators': [100, 200], 'max_depth': [None, 10]}\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'model': XGBClassifier(scale_pos_weight=1, use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "            'params': {'n_estimators': [100, 200], 'max_depth': [3, 6]}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(shap_dir, exist_ok=True)\n",
    "\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"LeadScoring_Simplified\")\n",
    "\n",
    "    results = []\n",
    "    best_models = {}\n",
    "\n",
    "    for name, model_info in models.items():\n",
    "        print(f\"\\nüîß Training: {name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocess', preprocessor),\n",
    "            ('model', model_info['model'])\n",
    "        ])\n",
    "\n",
    "        param_grid = {f\"model__{k}\": v for k, v in model_info['params'].items()}\n",
    "        search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grid,\n",
    "            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "            scoring='f1',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        search.fit(X_train, y_train)\n",
    "\n",
    "        y_val_pred = search.predict(X_val)\n",
    "        y_val_proba = search.predict_proba(X_val)[:, 1] if hasattr(search.best_estimator_.named_steps['model'], \"predict_proba\") else None\n",
    "\n",
    "        metrics = evaluate_classification_metrics(y_val, y_val_pred, y_val_proba)\n",
    "        results.append({\"model\": name, \"best_params\": search.best_params_, **metrics})\n",
    "        best_models[name] = search.best_estimator_\n",
    "\n",
    "        model_path = os.path.join(save_dir, f\"{name}_best_model.pkl\")\n",
    "        joblib.dump(search.best_estimator_, model_path)\n",
    "\n",
    "        with mlflow.start_run(run_name=name):\n",
    "            mlflow.log_params(search.best_params_)\n",
    "            mlflow.log_metrics(metrics)\n",
    "            mlflow.sklearn.log_model(search.best_estimator_, \"model\")\n",
    "\n",
    "            try:\n",
    "                print(f\"üîé Generating SHAP values for {name}...\")\n",
    "                fitted_preprocessor = search.best_estimator_.named_steps['preprocess']\n",
    "                X_val_proc = fitted_preprocessor.transform(X_val)\n",
    "                shap_matrix = X_val_proc.toarray() if hasattr(X_val_proc, \"toarray\") else X_val_proc\n",
    "                model_only = search.best_estimator_.named_steps['model']\n",
    "                if name in (\"RandomForest\", \"XGBoost\", \"LightGBM\", \"DecisionTree\"):\n",
    "                    explainer = shap.TreeExplainer(model_only)\n",
    "                else:\n",
    "                    explainer = shap.Explainer(model_only, shap_matrix)\n",
    "                shap_values = explainer(shap_matrix)\n",
    "                shap_path = os.path.join(shap_dir, f\"{name}_shap_summary.png\")\n",
    "                plt.figure()\n",
    "                shap.summary_plot(shap_values, shap_matrix, show=False)\n",
    "                plt.savefig(shap_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(shap_path, artifact_path=\"shap_plots\")\n",
    "                print(f\"‚úÖ SHAP saved & logged: {shap_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è SHAP failed for {name}: {e}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nüìä All Model Validation Metrics:\")\n",
    "    print(results_df[[\"model\", \"accuracy\", \"precision\", \"recall\", \"f1_score\", \"roc_auc\"]].to_string(index=False))\n",
    "\n",
    "    return results_df, best_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd349a3",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------\n",
    "# üíæ save_and_register_best_model_pipeline(...)\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# This function performs the final model selection, saving, and MLflow model registration steps:\n",
    "#\n",
    "# ‚úÖ Selects the best model based on highest F1 score from results_df\n",
    "# ‚úÖ Combines the selected model and preprocessor into a full pipeline\n",
    "# ‚úÖ Fits the full pipeline on the combined training + validation set\n",
    "# ‚úÖ Saves both the full pipeline and preprocessing pipeline using joblib\n",
    "# ‚úÖ Logs the model and artifacts to MLflow and registers it under the best model's name\n",
    "# ‚úÖ Transitions the newly registered model version to the \"Staging\" stage in MLflow Model Registry\n",
    "#\n",
    "# Parameters:\n",
    "# - results_df (DataFrame): Evaluation results of all models (must include 'model' and 'f1_score' columns)\n",
    "# - best_models (dict)    : Dictionary of trained models keyed by model name\n",
    "# - X_train_val           : Combined training and validation features\n",
    "# - y_train_val           : Combined training and validation labels\n",
    "# - preprocessor          : Preprocessing pipeline used before model training\n",
    "# - save_dir (str)        : Directory where models and pipelines are saved locally\n",
    "# - experiment_name (str) : MLflow experiment name for logging and tracking\n",
    "#\n",
    "# MLflow Requirements:\n",
    "# - MLflow tracking server must be running locally on port 5000\n",
    "# - MLflow model registry is used to version and stage the final model\n",
    "# ------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249938f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_and_register_best_model_pipeline(\n",
    "    results_df, best_models, X_train_val, y_train_val, preprocessor,\n",
    "    save_dir=\"saved_models\", experiment_name=\"LeadScoring_Simplified\"\n",
    "):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Select best model\n",
    "    best_row = results_df.sort_values(by=\"f1_score\", ascending=False).iloc[0]\n",
    "    best_model_name = best_row[\"model\"]\n",
    "    best_model = best_models[best_model_name]\n",
    "    print(f\"\\nüèÜ Best model selected: {best_model_name} (F1 = {best_row['f1_score']:.4f})\")\n",
    "\n",
    "    # 2. Final pipeline\n",
    "    final_pipeline = Pipeline([\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"model\", best_model.named_steps['model'] if hasattr(best_model, 'named_steps') else best_model)\n",
    "    ])\n",
    "    final_pipeline.fit(X_train_val, y_train_val)\n",
    "\n",
    "    # 3. Save final model pipeline locally\n",
    "    model_path = os.path.join(save_dir, f\"final_{best_model_name}_pipeline.pkl\")\n",
    "    joblib.dump(final_pipeline, model_path)\n",
    "    print(f\"‚úÖ Final pipeline saved at: {model_path}\")\n",
    "\n",
    "    # 4. Save preprocessor pipeline locally\n",
    "    preprocessor_path = os.path.join(save_dir, \"final_preprocessor.pkl\")\n",
    "    joblib.dump(preprocessor, preprocessor_path)\n",
    "    print(f\"‚úÖ Preprocessing pipeline saved at: {preprocessor_path}\")\n",
    "\n",
    "    # 5. Register to MLflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    client = MlflowClient()\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"Final_{best_model_name}\") as run:\n",
    "        run_id = run.info.run_id\n",
    "\n",
    "        # (a) Save local artifacts to MLflow\n",
    "        mlflow.log_artifact(model_path, artifact_path=\"model_artifacts\")\n",
    "        mlflow.log_artifact(preprocessor_path, artifact_path=\"preprocessing_artifacts\")\n",
    "\n",
    "        # (b) Log full pipeline as MLflow model (for loading later)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=final_pipeline,\n",
    "            artifact_path=\"sklearn_model\",\n",
    "            registered_model_name=best_model_name\n",
    "        )\n",
    "\n",
    "        print(f\"üîÅ Registering model to Model Registry: {best_model_name}\")\n",
    "        # --- Optionally: Get latest version programmatically (recommended, not just version=1)\n",
    "        try:\n",
    "            # List all versions in \"None\" stage (just logged)\n",
    "            versions = client.get_latest_versions(name=best_model_name, stages=[\"None\"])\n",
    "            if versions:\n",
    "                version = versions[0].version\n",
    "                client.transition_model_version_stage(\n",
    "                    name=best_model_name,\n",
    "                    version=version,\n",
    "                    stage=\"Staging\",\n",
    "                    archive_existing_versions=True\n",
    "                )\n",
    "                print(f\"‚úÖ Model '{best_model_name}' v{version} moved to 'Staging'.\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Could not find model version to move to 'Staging'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Transition to 'Staging' failed: {e}\")\n",
    "\n",
    "        print(f\"üèÉ View run: http://localhost:5000/#/experiments/{run.info.experiment_id}/runs/{run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561086e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_and_log_drift_reports(\n",
    "    X_train, X_val, X_test,\n",
    "    feature_names=None,\n",
    "    output_dir=\"drift_reports\",\n",
    "    mlflow_uri=\"http://127.0.0.1:5000\",\n",
    "    experiment_name=\"Drift\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates Evidently Data Drift reports comparing train/val/test,\n",
    "    saves them as HTML, and logs both artifacts and metrics into MLflow.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with drift metrics for each comparison.\n",
    "    \"\"\"\n",
    "\n",
    "    # Helper to ensure DataFrame\n",
    "    def ensure_df(data, feature_names):\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            return data\n",
    "        cols = feature_names if feature_names is not None else [f\"feature_{i}\" for i in range(data.shape[1])]\n",
    "        return pd.DataFrame(data, columns=cols)\n",
    "\n",
    "    X_train = ensure_df(X_train, feature_names)\n",
    "    X_val = ensure_df(X_val, feature_names)\n",
    "    X_test = ensure_df(X_test, feature_names)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    mlflow.set_tracking_uri(mlflow_uri)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    comparisons = [\n",
    "        (\"train_vs_val\", X_train, X_val),\n",
    "        (\"train_vs_test\", X_train, X_test),\n",
    "        (\"val_vs_test\", X_val, X_test)\n",
    "    ]\n",
    "\n",
    "    results_summary = {}\n",
    "\n",
    "    with mlflow.start_run(run_name=\"multi_split_drift\") as run:\n",
    "        for name, ref, curr in comparisons:\n",
    "            print(f\"üöÄ Running drift check: {name}\")\n",
    "            report = Report(metrics=[DataDriftPreset()])\n",
    "            report.run(reference_data=ref, current_data=curr)\n",
    "\n",
    "            # Save HTML artifact\n",
    "            html_path = os.path.join(output_dir, f\"{name}.html\")\n",
    "            report.save_html(html_path)\n",
    "            mlflow.log_artifact(html_path, artifact_path=\"evidently_html_reports\")\n",
    "\n",
    "            json_dict = report.as_dict()\n",
    "            drift_result = next((m[\"result\"] for m in json_dict[\"metrics\"] if m.get(\"metric\") == \"DataDriftTable\"), None)\n",
    "\n",
    "            if drift_result:\n",
    "                drift_ratio = drift_result.get(\"share_of_drifted_columns\", 0)\n",
    "                mlflow.log_metric(f\"{name}_drift_ratio\", round(drift_ratio, 4))\n",
    "\n",
    "                column_metrics = {}\n",
    "                for feature, vals in drift_result.get(\"drift_by_columns\", {}).items():\n",
    "                    score = vals.get(\"drift_score\")\n",
    "                    if score is not None:\n",
    "                        clean_name = feature.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "                        mlflow.log_metric(f\"{name}_{clean_name}\", round(score, 4))\n",
    "                        column_metrics[feature] = round(score, 4)\n",
    "\n",
    "                results_summary[name] = {\n",
    "                    \"drift_ratio\": round(drift_ratio, 4),\n",
    "                    \"column_scores\": column_metrics\n",
    "                }\n",
    "\n",
    "            print(f\"‚úÖ Drift metrics for {name} logged to MLflow.\\n\")\n",
    "\n",
    "        print(f\"üéØ Drift reports & metrics logged under run ID: {run.info.run_id}\")\n",
    "\n",
    "    return results_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382ee65",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------\n",
    "# üìä generate_and_log_drift_reports(...)\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# This function automates data drift detection using the Evidently library for multiple dataset splits:\n",
    "#\n",
    "# ‚úÖ Compares:\n",
    "#    - Train vs Validation\n",
    "#    - Train vs Test\n",
    "#    - Validation vs Test\n",
    "# ‚úÖ Generates HTML drift reports using Evidently's DataDriftPreset\n",
    "# ‚úÖ Saves the reports locally in a specified output directory\n",
    "# ‚úÖ Logs both the HTML artifacts and drift metrics to MLflow\n",
    "#\n",
    "# Parameters:\n",
    "# - X_train (array-like or DataFrame): Training feature data\n",
    "# - X_val (array-like or DataFrame): Validation feature data\n",
    "# - X_test (array-like or DataFrame): Test feature data\n",
    "# - feature_names (list, optional): List of feature names (used if inputs are arrays)\n",
    "# - output_dir (str): Directory path to save the HTML drift reports (default: \"drift_reports\")\n",
    "# - mlflow_uri (str): MLflow tracking URI (default: \"http://127.0.0.1:5000\")\n",
    "# - experiment_name (str): MLflow experiment name to log drift results (default: \"Drift\")\n",
    "#\n",
    "# Returns:\n",
    "# - dict: Summary of drift results for each pair, including drift ratios and per-feature scores\n",
    "#\n",
    "# MLflow Requirements:\n",
    "# - Must be connected to a local or remote MLflow tracking server\n",
    "# - Logs HTML artifacts and numerical drift scores as metrics\n",
    "#\n",
    "# Example Output:\n",
    "# {\n",
    "#     \"train_vs_val\": {\n",
    "#         \"drift_ratio\": 0.25,\n",
    "#         \"column_scores\": {\"Feature_A\": 0.67, \"Feature_B\": 0.55}\n",
    "#     },\n",
    "#     ...\n",
    "# }\n",
    "# ------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ddae62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 21:05:57 INFO mlflow.tracking.fluent: Experiment with name 'Drift' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data uploaded to PostgreSQL table 'lead' successfully.\n",
      "‚úÖ Data retrieved from PostgreSQL table 'lead':\n",
      "                            Prospect ID  Lead Number              Lead Origin  \\\n",
      "0  7927b2df-8bba-4d29-b9a2-b6e0beafe620       660737                      API   \n",
      "1  2a272436-5132-4136-86fa-dcc88c88f482       660728                      API   \n",
      "2  8cc8c611-a219-4f35-ad23-fdfd2656bd8a       660727  Landing Page Submission   \n",
      "3  0cc2df48-7cf4-4e39-9de9-19797f9b38cc       660719  Landing Page Submission   \n",
      "4  3256f628-e534-4826-9d63-4a8b88782852       660681  Landing Page Submission   \n",
      "\n",
      "      Lead Source Do Not Email Do Not Call  Converted  TotalVisits  \\\n",
      "0      Olark Chat           No          No          0          0.0   \n",
      "1  Organic Search           No          No          0          5.0   \n",
      "2  Direct Traffic           No          No          1          2.0   \n",
      "3  Direct Traffic           No          No          0          1.0   \n",
      "4          Google           No          No          1          2.0   \n",
      "\n",
      "   Total Time Spent on Website  Page Views Per Visit  ...  \\\n",
      "0                            0                   0.0  ...   \n",
      "1                          674                   2.5  ...   \n",
      "2                         1532                   2.0  ...   \n",
      "3                          305                   1.0  ...   \n",
      "4                         1428                   1.0  ...   \n",
      "\n",
      "  Get updates on DM Content    Lead Profile    City  \\\n",
      "0                        No          Select  Select   \n",
      "1                        No          Select  Select   \n",
      "2                        No  Potential Lead  Mumbai   \n",
      "3                        No          Select  Mumbai   \n",
      "4                        No          Select  Mumbai   \n",
      "\n",
      "  Asymmetrique Activity Index Asymmetrique Profile Index  \\\n",
      "0                   02.Medium                  02.Medium   \n",
      "1                   02.Medium                  02.Medium   \n",
      "2                   02.Medium                    01.High   \n",
      "3                   02.Medium                    01.High   \n",
      "4                   02.Medium                    01.High   \n",
      "\n",
      "  Asymmetrique Activity Score Asymmetrique Profile Score  \\\n",
      "0                        15.0                       15.0   \n",
      "1                        15.0                       15.0   \n",
      "2                        14.0                       20.0   \n",
      "3                        13.0                       17.0   \n",
      "4                        15.0                       18.0   \n",
      "\n",
      "  I agree to pay the amount through cheque  \\\n",
      "0                                       No   \n",
      "1                                       No   \n",
      "2                                       No   \n",
      "3                                       No   \n",
      "4                                       No   \n",
      "\n",
      "  A free copy of Mastering The Interview Last Notable Activity  \n",
      "0                                     No              Modified  \n",
      "1                                     No          Email Opened  \n",
      "2                                    Yes          Email Opened  \n",
      "3                                     No              Modified  \n",
      "4                                     No              Modified  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "üöÄ Running drift check: train_vs_val\n",
      "‚úÖ Drift metrics for train_vs_val logged to MLflow.\n",
      "\n",
      "üöÄ Running drift check: train_vs_test\n",
      "‚úÖ Drift metrics for train_vs_test logged to MLflow.\n",
      "\n",
      "üöÄ Running drift check: val_vs_test\n",
      "‚úÖ Drift metrics for val_vs_test logged to MLflow.\n",
      "\n",
      "üéØ Drift reports & metrics logged under run ID: eda2d36c43514d34ac58e11a136f469f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 21:06:09 INFO mlflow.tracking.fluent: Experiment with name 'LeadScoring_Simplified' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Training: LogisticRegression\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "üîé Generating SHAP values for LogisticRegression...\n",
      "‚úÖ SHAP saved & logged: shap_outputs\\LogisticRegression_shap_summary.png\n",
      "\n",
      "üîß Training: DecisionTree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "üîé Generating SHAP values for DecisionTree...\n",
      "‚úÖ SHAP saved & logged: shap_outputs\\DecisionTree_shap_summary.png\n",
      "\n",
      "üîß Training: RandomForest\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "üîé Generating SHAP values for RandomForest...\n",
      "‚úÖ SHAP saved & logged: shap_outputs\\RandomForest_shap_summary.png\n",
      "\n",
      "üîß Training: XGBoost\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "üîé Generating SHAP values for XGBoost...\n",
      "‚úÖ SHAP saved & logged: shap_outputs\\XGBoost_shap_summary.png\n",
      "\n",
      "üîß Training: LightGBM\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "üîé Generating SHAP values for LightGBM...\n",
      "‚úÖ SHAP saved & logged: shap_outputs\\LightGBM_shap_summary.png\n",
      "\n",
      "üìä All Model Validation Metrics:\n",
      "             model  accuracy  precision   recall  f1_score  roc_auc\n",
      "LogisticRegression  0.894481   0.861538 0.865169  0.863350 0.941985\n",
      "      DecisionTree  0.897727   0.857729 0.880618  0.869023 0.911804\n",
      "      RandomForest  0.924242   0.934650 0.863764  0.897810 0.958772\n",
      "           XGBoost  0.916126   0.912593 0.865169  0.888248 0.965837\n",
      "          LightGBM  0.918290   0.892308 0.896067  0.894184 0.965996\n",
      "\n",
      "üèÜ Best model selected: RandomForest (F1 = 0.8978)\n",
      "‚úÖ Final pipeline saved at: saved_models\\final_RandomForest_pipeline.pkl\n",
      "‚úÖ Preprocessing pipeline saved at: saved_models\\final_preprocessor.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'RandomForest'.\n",
      "2025/07/18 21:10:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: RandomForest, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Registering model to Model Registry: RandomForest\n",
      "‚úÖ Model 'RandomForest' v1 moved to 'Staging'.\n",
      "üèÉ View run: http://localhost:5000/#/experiments/958017348571353122/runs/0e6f690eebf04a12bedb0f46038c54ea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'RandomForest'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def run_lead_prediction_pipeline(\n",
    "    csv_file_path=None,\n",
    "    table_name=None,\n",
    "    experiment_name=\"LeadScoring_Simplified\",\n",
    "    save_dir=\"saved_models\",\n",
    "    shap_dir=\"shap_outputs\",\n",
    "    drift_dir=\"drift_reports\"\n",
    "):\n",
    "    # 1. Ingest\n",
    "    df = data_ingestion(csv_file_path=csv_file_path, table_name=\"lead\")\n",
    "    if df is None or not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"‚ùå Data ingestion failed: No DataFrame returned.\")\n",
    "\n",
    "    # 2. Drop columns (customize as needed)\n",
    "    drop_cols = [\n",
    "        'Prospect ID', 'Lead Number', 'Get updates on DM Content',\n",
    "        'Receive More Updates About Our Courses', 'I agree to pay the amount through cheque',\n",
    "        'Magazine', 'Update me on Supply Chain Content'\n",
    "    ]\n",
    "    df = df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "    # 3. Build preprocessor\n",
    "    preprocessor = build_full_pipeline(df)\n",
    "\n",
    "    # 4. Train/Val/Test split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    target_col = \"Converted\"\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    # 5. Data drift reports\n",
    "    feature_names = X_train.columns if hasattr(X_train, \"columns\") else None\n",
    "    generate_and_log_drift_reports(\n",
    "        X_train, X_val, X_test,\n",
    "        feature_names=feature_names,\n",
    "        output_dir=drift_dir,\n",
    "        mlflow_uri=\"http://127.0.0.1:5000\",\n",
    "        experiment_name=\"Drift\"\n",
    "    )\n",
    "\n",
    "    # 6. Model training & SHAP\n",
    "    results_df, best_models = train_log_and_shap_classification(\n",
    "        X_train, y_train, X_val, y_val, preprocessor,\n",
    "        save_dir=save_dir, shap_dir=shap_dir\n",
    "    )\n",
    "\n",
    "    # 7. Save & Register best model and preprocessor\n",
    "    X_train_val = pd.concat([X_train, X_val])\n",
    "    y_train_val = pd.concat([y_train, y_val])\n",
    "    save_and_register_best_model_pipeline(\n",
    "        results_df, best_models, X_train_val, y_train_val, preprocessor,\n",
    "        save_dir=save_dir, experiment_name=experiment_name\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_lead_prediction_pipeline(csv_file_path=\"Lead Scoring.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a5e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leadscoring_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
